{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook the performance of some Python scripts before/after Ray is investigated. \n",
    "\n",
    "The exerices are derived from https://github.com/ray-project/tutorial. Here some of them are solved, and have passed their timing requirements. The notebook will ideally be extended to more complex algorithms, preferrably RL algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ray.init(num_cpus=8, redirect_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 1: Simple Data Parallel Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### BEFORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [0, 1, 2, 3]\n",
      "time in seconds without Ray: 4.004085063934326\n"
     ]
    }
   ],
   "source": [
    "# This function is a proxy for a more interesting and computationally\n",
    "# intensive function.\n",
    "def slow_function(i):\n",
    "    time.sleep(1)\n",
    "    return i\n",
    "\n",
    "# Sleep a little to improve the accuracy of the timing measurements below.\n",
    "# We do this because workers may still be starting up in the background.\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "results = []\n",
    "for i in range(4):\n",
    "    results.append(slow_function(i))\n",
    "\n",
    "end_time = time.time()\n",
    "duration_slow = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds without Ray: {}'.format(duration_slow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [0, 1, 2, 3]\n",
      "time in seconds with Ray: 1.0028748512268066\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def fast_function(i):\n",
    "    time.sleep(1)\n",
    "    return i\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "object_ids = [fast_function.remote(i) for i in range(4)]\n",
    "results = ray.get(object_ids)\n",
    "\n",
    "end_time = time.time()\n",
    "duration_fast = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds with Ray: {}'.format(duration_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 2: Parallel Data Processing with Task Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### BEFORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 4000.0\n",
      "time in seconds without Ray: 1.6527800559997559\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    time.sleep(0.1)\n",
    "    return np.ones((1000, 100))\n",
    "\n",
    "def normalize_data(data):\n",
    "    time.sleep(0.1)\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "def extract_features(normalized_data):\n",
    "    time.sleep(0.1)\n",
    "    return np.hstack([normalized_data, normalized_data ** 2])\n",
    "\n",
    "def compute_loss(features):\n",
    "    num_data, dim = features.shape\n",
    "    time.sleep(0.1)\n",
    "    return np.sum((np.dot(features, np.ones(dim)) - np.ones(num_data)) ** 2)\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "losses = []\n",
    "for filename in ['file1', 'file2', 'file3', 'file4']:\n",
    "    data = load_data(filename)\n",
    "    normalized_data = normalize_data(data)\n",
    "    features = extract_features(normalized_data)\n",
    "    loss = compute_loss(features)\n",
    "    losses.append(loss)\n",
    "\n",
    "loss = sum(losses)\n",
    "\n",
    "end_time = time.time()\n",
    "duration_slow = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(loss))\n",
    "print('time in seconds without Ray: {}'.format(duration_slow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 4000.0\n",
      "time in seconds with Ray: 0.4228091239929199\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def load_data_fast(filename):\n",
    "    time.sleep(0.1)\n",
    "    return np.ones((1000, 100))\n",
    "\n",
    "@ray.remote\n",
    "def normalize_data_fast(data):\n",
    "    time.sleep(0.1)\n",
    "    return data - np.mean(data, axis=0)\n",
    "\n",
    "@ray.remote\n",
    "def extract_features_fast(normalized_data):\n",
    "    time.sleep(0.1)\n",
    "    return np.hstack([normalized_data, normalized_data ** 2])\n",
    "\n",
    "@ray.remote\n",
    "def compute_loss_fast(features):\n",
    "    num_data, dim = features.shape\n",
    "    time.sleep(0.1)\n",
    "    return np.sum((np.dot(features, np.ones(dim)) - np.ones(num_data)) ** 2)\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "files = ['file1', 'file2', 'file3', 'file4']\n",
    "\n",
    "data_obj = [load_data_fast.remote(filename) for filename in files]\n",
    "normalized_data_obj = [normalize_data_fast.remote(dt) for dt in data_obj]\n",
    "features_obj = [extract_features_fast.remote(norm_dt) for norm_dt in normalized_data_obj]\n",
    "losses_obj = [compute_loss_fast.remote(feature) for feature in features_obj]\n",
    "\n",
    "loss = sum(ray.get(losses_obj))\n",
    "\n",
    "end_time = time.time()\n",
    "duration_fast = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(loss))\n",
    "print('time in seconds with Ray: {}'.format(duration_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 3: Tree of tasks executed in parallel (Tree Reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### BEFORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [ 40320.  40320.  40320. ...,  40320.  40320.  40320.]\n",
      "time in seconds without Ray: 4.524723052978516\n"
     ]
    }
   ],
   "source": [
    "# This is a proxy for a function which generates some data.\n",
    "def create_data(i):\n",
    "    time.sleep(0.3)\n",
    "    return i * np.ones(10000)\n",
    "\n",
    "# This is a proxy for an expensive aggregation step (which is also\n",
    "# commutative and associative so it can be used in a tree-reduce).\n",
    "def aggregate_data(x, y):\n",
    "    time.sleep(0.3)\n",
    "    return x * y\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "vectors = [create_data(i + 1) for i in range(8)]\n",
    "\n",
    "# For clarity the aggregation below is written as seperate functions,\n",
    "# but it should be done using a while loop\n",
    "result = aggregate_data(vectors[0], vectors[1])\n",
    "result = aggregate_data(result, vectors[2])\n",
    "result = aggregate_data(result, vectors[3])\n",
    "result = aggregate_data(result, vectors[4])\n",
    "result = aggregate_data(result, vectors[5])\n",
    "result = aggregate_data(result, vectors[6])\n",
    "result = aggregate_data(result, vectors[7])\n",
    "\n",
    "end_time = time.time()\n",
    "duration_slow = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(result))\n",
    "print('time in seconds without Ray: {}'.format(duration_slow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [ 40320.  40320.  40320. ...,  40320.  40320.  40320.]\n",
      "time in seconds with Ray: 1.2474958896636963\n"
     ]
    }
   ],
   "source": [
    "# This is a proxy for a function which generates some data.\n",
    "@ray.remote\n",
    "def create_data_fast(i):\n",
    "    time.sleep(0.3)\n",
    "    return i * np.ones(10000)\n",
    "\n",
    "# This is a proxy for an expensive aggregation step (which is also\n",
    "# commutative and associative so it can be used in a tree-reduce).\n",
    "@ray.remote\n",
    "def aggregate_data_fast(x, y):\n",
    "    time.sleep(0.3)\n",
    "    return x * y\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "# data is generated in parallel\n",
    "vectors_obj = [create_data_fast.remote(i+1) for i in range(8)]\n",
    "\n",
    "# Again for clarity separate functions are written, but while loop\n",
    "# should ideally be used. \n",
    "# Speeding up tree aggregation below by using Ray:\n",
    "result01 = aggregate_data_fast.remote(vectors_obj[0], vectors_obj[1])\n",
    "result23 = aggregate_data_fast.remote(vectors_obj[2], vectors_obj[3])\n",
    "result45 = aggregate_data_fast.remote(vectors_obj[4], vectors_obj[5])\n",
    "result67 = aggregate_data_fast.remote(vectors_obj[6], vectors_obj[7])\n",
    "\n",
    "result0123 = aggregate_data_fast.remote(result01, result23)\n",
    "result4567 = aggregate_data_fast.remote(result45, result67)\n",
    "\n",
    "final_result = aggregate_data_fast.remote(result0123, result4567)\n",
    "\n",
    "result = ray.get(final_result)\n",
    "\n",
    "end_time = time.time()\n",
    "duration_fast = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(result))\n",
    "print('time in seconds with Ray: {}'.format(duration_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 4: Hyper Parameter sweep by Nested Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### BEFORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [20, 20, 20]\n",
      "time in seconds without Ray: 1.949739933013916\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(data):\n",
    "    time.sleep(0.03)\n",
    "    return 1\n",
    "\n",
    "def train_model(hyperparameters):\n",
    "    result = 0\n",
    "    for i in range(10):\n",
    "        result += sum([compute_gradient(j) for j in range(2)])\n",
    "    return result\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "# Run some hyperparaameter experiments.\n",
    "results = []\n",
    "for hyperparameters in [{'learning_rate': 1e-1, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-2, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-3, 'batch_size': 100}]:\n",
    "    results.append(train_model(hyperparameters))\n",
    "\n",
    "end_time = time.time()\n",
    "duration_slow = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds without Ray: {}'.format(duration_slow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [20, 20, 20]\n",
      "time in seconds with Ray: 0.03414201736450195\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def compute_gradient_fast(data):\n",
    "    time.sleep(0.03)\n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def train_model_fast(hyperparameters):\n",
    "    # EXERCISE: After you turn \"compute_gradient\" into a remote function,\n",
    "    # you will need to call it with \".remote\". The results must be retrieved\n",
    "    # with \"ray.get\" before \"sum\" is called.\n",
    "    grad = sum(ray.get([compute_gradient_fast.remote(j) for j in range(2)]))\n",
    "    return [grad for _ in range(10)]\n",
    "\n",
    "# Sleep a little to improve the accuracy of the timing measurements below.\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "# Run some hyperparaameter experiments.\n",
    "results = []\n",
    "hyperparameters_list = [{'learning_rate': 1e-1, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-2, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-3, 'batch_size': 100}]\n",
    "\n",
    "results_obj = [train_model_fast.remote(params) for params in hyperparameters_list]\n",
    "results = [sum(res) for res in ray.get(results_obj)]\n",
    "\n",
    "end_time = time.time()\n",
    "duration_fast = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds with Ray: {}'.format(duration_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: Using Actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Ray Doc: Sometimes you need a \"worker\" process to have \"state\". For example, that state might be a neural network, a simulator environment, a counter, or something else entirely. However, remote functions are side-effect free. That is, they operate on inputs and produce outputs, but they don't change the state of the worker they execute on.\n",
    "\n",
    "Actors are different. When we instantiate an actor, a brand new worker is created, and all methods that are called on that actor are executed on the newly created worker.\n",
    "\n",
    "This means that with a single actor, no parallelism can be achieved because calls to the actor's methods will be executed one at a time. However, multiple actors can be created and methods can be executed on them in parallel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEFORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]\n",
      "time in seconds without Ray: 5.021368980407715\n"
     ]
    }
   ],
   "source": [
    "class Foo(object):\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def increment(self):\n",
    "        time.sleep(0.5)\n",
    "        self.counter += 1\n",
    "        return self.counter\n",
    "    \n",
    "# Create two Foo objects.\n",
    "f1 = Foo()\n",
    "f2 = Foo()\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "f1.reset()\n",
    "f2.reset()\n",
    "\n",
    "results = []\n",
    "for _ in range(5):\n",
    "    results.append(f1.increment())\n",
    "    results.append(f2.increment())\n",
    "\n",
    "end_time = time.time()\n",
    "duration_slow = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds without Ray: {}'.format(duration_slow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [1, 1, 2, 2, 3, 3, 4, 4, 5, 5]\n",
      "time in seconds with Ray: 2.524989128112793\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "class Foo_fast(object):\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def increment(self):\n",
    "        time.sleep(0.5)\n",
    "        self.counter += 1\n",
    "        return self.counter\n",
    "    \n",
    "# Create two Foo objects.\n",
    "f1 = Foo_fast.remote()\n",
    "f2 = Foo_fast.remote()\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "# Reset the actor state so that we can run this cell multiple times without\n",
    "# changing the results.\n",
    "f1.reset.remote()\n",
    "f2.reset.remote()\n",
    "\n",
    "# We want to parallelize this code. However, it is not straightforward to\n",
    "# make \"increment\" a remote function, because state is shared (the value of\n",
    "# \"self.counter\") between subsequent calls to \"increment\". In this case, it\n",
    "# makes sense to use actors.\n",
    "results_obj = [[f1.increment.remote(), f2.increment.remote()] for _ in range(5)]\n",
    "results = ray.get(sum(results_obj,[]))\n",
    "\n",
    "end_time = time.time()\n",
    "duration_fast = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds with Ray: {}'.format(duration_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: Speed up Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neural_net_weights = {'variable{}'.format(i): np.random.normal(size=1000000)\n",
    "                      for i in range(50)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the time required to serialize the neural net weights and copy them into the object store using Ray versus the time required to pickle and unpickle the weights. \n",
    "\n",
    "The big win should be with the time required for deserialization.\n",
    "\n",
    "ray.put leverages multiple threads when serializing large objects. Note that this is not possible with pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ray - serializing\n",
      "CPU times: user 280 ms, sys: 965 ms, total: 1.25 s\n",
      "Wall time: 1.01 s\n",
      "\n",
      "Ray - deserializing\n",
      "CPU times: user 719 µs, sys: 628 µs, total: 1.35 ms\n",
      "Wall time: 1.25 ms\n",
      "\n",
      "pickle - serializing\n",
      "CPU times: user 296 ms, sys: 405 ms, total: 701 ms\n",
      "Wall time: 1.06 s\n",
      "\n",
      "pickle - deserializing\n",
      "CPU times: user 174 ms, sys: 141 ms, total: 315 ms\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "print('Ray - serializing')\n",
    "%time x_id = ray.put(neural_net_weights)\n",
    "print('\\nRay - deserializing')\n",
    "%time x_val = ray.get(x_id)\n",
    "\n",
    "print('\\npickle - serializing')\n",
    "%time serialized = pickle.dumps(neural_net_weights)\n",
    "print('\\npickle - deserializing')\n",
    "%time deserialized = pickle.loads(serialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ray.put to avoid copying the neural net weights to the object store multiple times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "time in seconds with Ray: 0.5597741603851318\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def use_weights(weights, i):\n",
    "    return i\n",
    "\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "weights_id = ray.put(neural_net_weights)\n",
    "results = ray.get([use_weights.remote(weights_id, i)\n",
    "                   for i in range(20)])\n",
    "\n",
    "end_time = time.time()\n",
    "duration_fast = end_time - start_time\n",
    "\n",
    "print('result: {}'.format(results))\n",
    "print('time in seconds with Ray: {}'.format(duration_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
